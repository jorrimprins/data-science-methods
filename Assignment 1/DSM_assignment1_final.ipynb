{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "**Deadline**:  11/09/2019, 9.59am\n",
    "\n",
    "**Names and student numbers:**\n",
    "1. Dante van der Heijden (11020075)\n",
    "2. Jorrim Prins (11038934)\n",
    "3. Vien Dinh (11002115)\n",
    "\n",
    "**Declaration of Originality**\n",
    "\n",
    "We whose names are given under 1., 2. and 3. above declare that:\n",
    "1. These solutions are solely our own work.\n",
    "2. We have not made (part of) these solutions available to any other student.\n",
    "\n",
    "## Instructions for completing and submitting the assignment\n",
    "Please pay attention to the following instructions:\n",
    "1. Please follow carefully the steps outlined in the assignment. If you cannot solve an exercise and this hinders continuing with subsequent exercises, try to find a way to work around it and give a clear explanation for the solution you have chosen.\n",
    "2. Submit your work in the form of a Jupyter notebook via Canvas, before the deadline. Your notebook should not give errors when executed with `Run All`.\n",
    "4. You are allowed to work on the assignment in groups of 2 or 3 students and to submit together. Before you submit, you and your team members have to register as an **Assignment group** on Canvas. Only a single member of each group has to submit the notebook. Please do **NOT** submit the same notebook multiple times!\n",
    "5. Please write your names also inside this markdown cell, under **Names and student numbers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: importing the relevant libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** import all the libraries you are using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: using the Python Standard Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** write a function called `sort_words`. The function should have a single argument, which is always a string of words separated by spaces. For example, `sample` in the cell below is such a string. The function should return another string containing the same words separated by spaces, but now the words must be ordered alphabetically by their first letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'are coding exercises fun or what?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"coding what? fun are exercises or\"\n",
    "def sort_words(string):\n",
    "    string_split = string.split()\n",
    "    string_split.sort()\n",
    "    return \" \".join(string_split)\n",
    "sort_words(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** below you find three cells. In the first cell three NumPy objects (`v`, `u` and `A`) are defined, depending on an integer parameter `n`. In the second cell, these objects are used to compute a quantity that you might know from your linear algebra course. In this exercise, you have to perform two tasks:\n",
    "* in the third cell, compute the quantity of the second cell again, but now without the use of any (for) loops. Print the result to verify that your code indeed computes the same quantity.\n",
    "* use Python's `time` module to measure the time the computations in the second and third cell take, separately. Notice that if you increase `n` (to for example 2000), the relative difference in computational efficiency grows rapidly.\n",
    "\n",
    "[NB: When your run a vectorized computation for the first time, Python loads some additional libraries in the background. This takes additional time. Therefore, you have to run the vectorized computation (at least) twice to get a good estimate of the computational time.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9162749999999997"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n = 100\n",
    "v = np.random.normal(size=n)\n",
    "u = np.random.normal(size=n)\n",
    "A = np.random.normal(size=(n,n))\n",
    "time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-78.54616835889931\n",
      "0.010471105575561523\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = 0\n",
    "\n",
    "for i in range(len(v)):\n",
    "    for j in range(len(u)):\n",
    "        result += v[i]*A[i,j]*u[j]\n",
    "        \n",
    "print(result)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-78.54616835889868\n",
      "0.002950906753540039\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(np.dot(np.dot(v,A),u))\n",
    "time.process_time()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: wrangling and analyzing Twitter sentiment data\n",
    "This part of the assignment is about wrangling and analyzing Twitter sentiment data for six airline companies:\n",
    "\n",
    "|**Name Airline**|**@username**|\n",
    "|:-------|:-------------|\n",
    "|American Airlines       |@AmericanAir           |\n",
    "|JetBlue Airways        |@JetBlue              |\n",
    "|Southwest Airlines       |@SouthwestAir           |\n",
    "|United Airlines        |@united              |\n",
    "|US Airways        |@USAirways              |\n",
    "|Virgin America       |@VirginAmerica             |\n",
    "\n",
    "The dataset `airline_twitter_sentiment.csv` consists of more than 14.000 tweets sent on 9 consecutive days in February 2015, all addressing one (or more) of the aforementioned airlines via the @username syntax. The text of the tweets can be found in the `text` column of the dataset. Furthermore, a machine learning algorithm has analyzed the content of the tweets and categorized the sentiment as positive, neutral or negative. This can be found in the `airline_sentiment` column. The machine learning algorithm also estimates the probability that it identified the correct sentiment, which is given in the `airline_sentiment:confidence` column. Another relevant column is called `tweet_created`, giving the time and day at which the tweet was sent.\n",
    "\n",
    "(Note: US Airways was integreted into American Airlines in October 2015. Since our dataset is from February 2015, we will consider them as separate airlines.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** import the dataset `airline_twitter_sentiment.csv` and turn it into a DataFrame called `df`. Print the total number of tweets in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14694\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('airline_twitter_sentiment.csv')\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** print the first 10 rows of the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>681448223</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:57</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cuschoolie1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica help, left expensive headphones...</td>\n",
       "      <td>[33.94209449, -118.40410103]</td>\n",
       "      <td>2/23/15 21:10</td>\n",
       "      <td>5.700880e+17</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681452067</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 0:41</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Flight Booking Problems</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERBARAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united very exasperating I'm having a difficu...</td>\n",
       "      <td>[41.86591215, -87.6231126]</td>\n",
       "      <td>2/20/15 21:36</td>\n",
       "      <td>5.690080e+17</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>681451479</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 4:43</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CoachMcRoberts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Can you help me get a flight out tonig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/21/15 16:58</td>\n",
       "      <td>5.693000e+17</td>\n",
       "      <td>Oxford, MS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681456798</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:27</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Flight Booking Problems</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4starcashier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir 4/9/14, I need to fly from GSP t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/17/15 12:37</td>\n",
       "      <td>5.677850e+17</td>\n",
       "      <td>Des Moines, Iowa</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681461929</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:50</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Damaged Luggage</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WTFloris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways Oh yes, because I had loads of time...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/21/15 1:54</td>\n",
       "      <td>5.690730e+17</td>\n",
       "      <td>Raxacoricofallapatorius</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>681453541</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 9:04</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lorenzosimpson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united i now see it's 72 hours. Thanks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/18/15 17:50</td>\n",
       "      <td>5.682260e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>681457766</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 7:40</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WeChiefMusic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue ok thanks. Safety first.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/22/15 19:57</td>\n",
       "      <td>5.697080e+17</td>\n",
       "      <td>Planet Brooklyn</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>681455921</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 0:59</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stefughknee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir when can I start Flight Booking ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/19/15 13:12</td>\n",
       "      <td>5.685180e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>681452831</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 2:38</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnay777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united LGJW7B. I voluntarily rerouted; 1st le...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/19/15 18:06</td>\n",
       "      <td>5.685930e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>681454491</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 2:03</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amymiller305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir customer service at FLL, BWI,and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 4:29</td>\n",
       "      <td>5.701990e+17</td>\n",
       "      <td>South Florida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  681448223    False   finalized                   3      2/25/15 1:57   \n",
       "1  681452067    False   finalized                   3      2/25/15 0:41   \n",
       "2  681451479    False   finalized                   3      2/25/15 4:43   \n",
       "3  681456798    False   finalized                   3      2/25/15 3:27   \n",
       "4  681461929    False   finalized                   3      2/25/15 3:50   \n",
       "5  681453541    False   finalized                   3      2/25/15 9:04   \n",
       "6  681457766    False   finalized                   3      2/25/15 7:40   \n",
       "7  681455921    False   finalized                   3      2/25/15 0:59   \n",
       "8  681452831    False   finalized                   3      2/25/15 2:38   \n",
       "9  681454491    False   finalized                   3      2/25/15 2:03   \n",
       "\n",
       "  airline_sentiment  airline_sentiment:confidence           negativereason  \\\n",
       "0          negative                        1.0000   Customer Service Issue   \n",
       "1          negative                        1.0000  Flight Booking Problems   \n",
       "2           neutral                        1.0000                      NaN   \n",
       "3          negative                        1.0000  Flight Booking Problems   \n",
       "4          negative                        1.0000          Damaged Luggage   \n",
       "5           neutral                        1.0000                      NaN   \n",
       "6          positive                        1.0000                      NaN   \n",
       "7           neutral                        1.0000                      NaN   \n",
       "8           neutral                        0.6709                      NaN   \n",
       "9          negative                        1.0000   Customer Service Issue   \n",
       "\n",
       "   negativereason:confidence airline_sentiment_gold            name  \\\n",
       "0                     1.0000                    NaN     Cuschoolie1   \n",
       "1                     0.6939                    NaN        MERBARAT   \n",
       "2                        NaN                    NaN  CoachMcRoberts   \n",
       "3                     1.0000                    NaN    4starcashier   \n",
       "4                     0.6663                    NaN        WTFloris   \n",
       "5                        NaN                    NaN  lorenzosimpson   \n",
       "6                        NaN                    NaN    WeChiefMusic   \n",
       "7                        NaN                    NaN     stefughknee   \n",
       "8                     0.0000                    NaN         jnay777   \n",
       "9                     0.6804                    NaN    amymiller305   \n",
       "\n",
       "  negativereason_gold  retweet_count  \\\n",
       "0                 NaN              0   \n",
       "1                 NaN              0   \n",
       "2                 NaN              0   \n",
       "3                 NaN              0   \n",
       "4                 NaN              0   \n",
       "5                 NaN              0   \n",
       "6                 NaN              0   \n",
       "7                 NaN              0   \n",
       "8                 NaN              0   \n",
       "9                 NaN              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  @VirginAmerica help, left expensive headphones...   \n",
       "1  @united very exasperating I'm having a difficu...   \n",
       "2  @united Can you help me get a flight out tonig...   \n",
       "3  @SouthwestAir 4/9/14, I need to fly from GSP t...   \n",
       "4  @USAirways Oh yes, because I had loads of time...   \n",
       "5            @united i now see it's 72 hours. Thanks   \n",
       "6                  @JetBlue ok thanks. Safety first.   \n",
       "7  @SouthwestAir when can I start Flight Booking ...   \n",
       "8  @united LGJW7B. I voluntarily rerouted; 1st le...   \n",
       "9  @SouthwestAir customer service at FLL, BWI,and...   \n",
       "\n",
       "                    tweet_coord  tweet_created      tweet_id  \\\n",
       "0  [33.94209449, -118.40410103]  2/23/15 21:10  5.700880e+17   \n",
       "1    [41.86591215, -87.6231126]  2/20/15 21:36  5.690080e+17   \n",
       "2                           NaN  2/21/15 16:58  5.693000e+17   \n",
       "3                           NaN  2/17/15 12:37  5.677850e+17   \n",
       "4                           NaN   2/21/15 1:54  5.690730e+17   \n",
       "5                           NaN  2/18/15 17:50  5.682260e+17   \n",
       "6                           NaN  2/22/15 19:57  5.697080e+17   \n",
       "7                           NaN  2/19/15 13:12  5.685180e+17   \n",
       "8                           NaN  2/19/15 18:06  5.685930e+17   \n",
       "9                           NaN   2/24/15 4:29  5.701990e+17   \n",
       "\n",
       "            tweet_location               user_timezone  \n",
       "0            Washington DC                       Quito  \n",
       "1              Chicago, IL  Central Time (US & Canada)  \n",
       "2               Oxford, MS                         NaN  \n",
       "3         Des Moines, Iowa  Central Time (US & Canada)  \n",
       "4  Raxacoricofallapatorius                   Amsterdam  \n",
       "5                      NaN  Eastern Time (US & Canada)  \n",
       "6          Planet Brooklyn      Atlantic Time (Canada)  \n",
       "7                      NaN                         NaN  \n",
       "8                      NaN                         NaN  \n",
       "9           South Florida                          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** create a list of the names of the columns of the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unit_id',\n",
       " '_golden',\n",
       " '_unit_state',\n",
       " '_trusted_judgments',\n",
       " '_last_judgment_at',\n",
       " 'airline_sentiment',\n",
       " 'airline_sentiment:confidence',\n",
       " 'negativereason',\n",
       " 'negativereason:confidence',\n",
       " 'airline_sentiment_gold',\n",
       " 'name',\n",
       " 'negativereason_gold',\n",
       " 'retweet_count',\n",
       " 'text',\n",
       " 'tweet_coord',\n",
       " 'tweet_created',\n",
       " 'tweet_id',\n",
       " 'tweet_location',\n",
       " 'user_timezone']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** during the creation of the dataset some lines/rows were duplicated. Remove them from `df`, such that the DataFrame `df` does not contain any duplicates anymore. Count the total number of duplicates and print this number in a nice sentence that explains the meaning of the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All duplicate rows of the dataset have been deleted. This was a total of 54 rows.\n"
     ]
    }
   ],
   "source": [
    "rows_df = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "rows_df_new = df.shape[0]\n",
    "print('All duplicate rows of the dataset have been deleted. This was a total of', rows_df - rows_df_new, 'rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** the machine learning algorithm is not always able to extract a sentiment from the tweet. This is reflected in a missing `airline_sentiment` value. Remove the lines with a missing airline sentiment from the `df`. As in the previous exercise, report the number of discarded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tweets with unknown sentiment have been deleted. This was a total of 36 tweets.\n"
     ]
    }
   ],
   "source": [
    "rows_df = df.shape[0]\n",
    "df = df[df['airline_sentiment'].notna()]\n",
    "rows_df_new = df.shape[0]\n",
    "print('All tweets with unknown sentiment have been deleted. This was a total of', rows_df - rows_df_new, 'tweets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** the column `airline_sentiment:confidence` represents the probability that the machine learning algorithm predicted the correct sentiment. Remove the lines from `df` with an airline-sentiment confidence below 0.50. Report the number of discarded tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tweets with low-confidence sentiment have been deleted. This was a total of 235 tweets.\n"
     ]
    }
   ],
   "source": [
    "rows_df = df.shape[0]\n",
    "df = df[df['airline_sentiment:confidence'] >= 0.5]\n",
    "rows_df_new = df.shape[0]\n",
    "print('All tweets with low-confidence sentiment have been deleted. This was a total of', rows_df - rows_df_new, 'tweets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10:** the columns `text` contains the text of the tweets. Remove the lines from `df` with tweets containing less than 50 characters. Report the number of discarded tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tweets with less than 50 characters have been deleted. This was a total of 1534 tweets.\n"
     ]
    }
   ],
   "source": [
    "rows_df = df.shape[0]\n",
    "df = df[df['text'].str.len() >= 50]\n",
    "rows_df_new = df.shape[0]\n",
    "print('All tweets with less than 50 characters have been deleted. This was a total of', rows_df - rows_df_new, 'tweets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11:** print a frequency table for the total number of positive, neutral and negative tweets in the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    8650\n",
       "neutral     2419\n",
       "positive    1766\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12:** sort the rows in the DataFrame by the time the tweet was created (use the `tweet_created` column). The tweet that was created first, should be on top of the DataFrame. Then, reset the index of the DataFrame, such that the first row has index 0, the second row has index 1, etcetera. Make sure that the old index does **not** become an additional column in the DataFrame. Finally, print the last 10 rows of the resulting DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment:confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason:confidence</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12825</th>\n",
       "      <td>681677275</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 19:16</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jacquelinewins6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir \\nIt's not what happens to us tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:56</td>\n",
       "      <td>5.702810e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12826</th>\n",
       "      <td>681463330</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 6:54</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chone1984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir pretty lame response to a two pag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:57</td>\n",
       "      <td>5.702810e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12827</th>\n",
       "      <td>681677274</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 18:56</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chone1984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir pretty lame response to a two pag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:57</td>\n",
       "      <td>5.702810e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12828</th>\n",
       "      <td>681677273</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 19:39</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robkoenigld</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir why am I continually getting put ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:58</td>\n",
       "      <td>5.702820e+17</td>\n",
       "      <td>indialantic, fl</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12829</th>\n",
       "      <td>681463328</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 1:51</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robkoenigld</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir why am I continually getting put ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:58</td>\n",
       "      <td>5.702820e+17</td>\n",
       "      <td>indialantic, fl</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>681454365</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 8:55</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>srsable7290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir what is the status of the bag ch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:58</td>\n",
       "      <td>5.702820e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12831</th>\n",
       "      <td>681677272</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 18:49</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMesaLaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir don't worry you won't steal my mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:59</td>\n",
       "      <td>5.702820e+17</td>\n",
       "      <td>Greater New England Area</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12832</th>\n",
       "      <td>681463324</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 3:32</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MrsPang725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir lost my cats, missed their flight...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:59</td>\n",
       "      <td>5.702820e+17</td>\n",
       "      <td>City by the Bay</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12833</th>\n",
       "      <td>681677271</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 19:13</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>0.6471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MrsPang725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir lost my cats, missed their flight...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:59</td>\n",
       "      <td>5.702820e+17</td>\n",
       "      <td>City by the Bay</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834</th>\n",
       "      <td>681463326</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/25/15 9:27</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6712</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMesaLaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir don't worry you won't steal my mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/15 9:59</td>\n",
       "      <td>5.702820e+17</td>\n",
       "      <td>Greater New England Area</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "12825  681677275    False   finalized                   3     2/25/15 19:16   \n",
       "12826  681463330    False   finalized                   3      2/25/15 6:54   \n",
       "12827  681677274    False   finalized                   3     2/25/15 18:56   \n",
       "12828  681677273    False   finalized                   3     2/25/15 19:39   \n",
       "12829  681463328    False   finalized                   3      2/25/15 1:51   \n",
       "12830  681454365    False   finalized                   3      2/25/15 8:55   \n",
       "12831  681677272    False   finalized                   3     2/25/15 18:49   \n",
       "12832  681463324    False   finalized                   3      2/25/15 3:32   \n",
       "12833  681677271    False   finalized                   3     2/25/15 19:13   \n",
       "12834  681463326    False   finalized                   3      2/25/15 9:27   \n",
       "\n",
       "      airline_sentiment  airline_sentiment:confidence          negativereason  \\\n",
       "12825          negative                        1.0000              Can't Tell   \n",
       "12826          negative                        1.0000  Customer Service Issue   \n",
       "12827          negative                        1.0000  Customer Service Issue   \n",
       "12828          negative                        1.0000  Customer Service Issue   \n",
       "12829          negative                        1.0000  Customer Service Issue   \n",
       "12830           neutral                        0.6655                     NaN   \n",
       "12831          negative                        1.0000              Can't Tell   \n",
       "12832          negative                        1.0000            Lost Luggage   \n",
       "12833          negative                        1.0000            Lost Luggage   \n",
       "12834          negative                        0.6712              Can't Tell   \n",
       "\n",
       "       negativereason:confidence airline_sentiment_gold             name  \\\n",
       "12825                     0.6590                    NaN  jacquelinewins6   \n",
       "12826                     0.6701                    NaN        chone1984   \n",
       "12827                     1.0000                    NaN        chone1984   \n",
       "12828                     1.0000                    NaN      robkoenigld   \n",
       "12829                     1.0000                    NaN      robkoenigld   \n",
       "12830                     0.0000                    NaN      srsable7290   \n",
       "12831                     1.0000                    NaN         EMesaLaw   \n",
       "12832                     0.6612                    NaN       MrsPang725   \n",
       "12833                     0.6471                    NaN       MrsPang725   \n",
       "12834                     0.3356                    NaN         EMesaLaw   \n",
       "\n",
       "      negativereason_gold  retweet_count  \\\n",
       "12825                 NaN              0   \n",
       "12826                 NaN              0   \n",
       "12827                 NaN              0   \n",
       "12828                 NaN              0   \n",
       "12829                 NaN              0   \n",
       "12830                 NaN              0   \n",
       "12831                 NaN              0   \n",
       "12832                 NaN              0   \n",
       "12833                 NaN              0   \n",
       "12834                 NaN              0   \n",
       "\n",
       "                                                    text tweet_coord  \\\n",
       "12825  @AmericanAir \\nIt's not what happens to us tha...         NaN   \n",
       "12826  @AmericanAir pretty lame response to a two pag...         NaN   \n",
       "12827  @AmericanAir pretty lame response to a two pag...         NaN   \n",
       "12828  @AmericanAir why am I continually getting put ...         NaN   \n",
       "12829  @AmericanAir why am I continually getting put ...         NaN   \n",
       "12830  @SouthwestAir what is the status of the bag ch...         NaN   \n",
       "12831  @AmericanAir don't worry you won't steal my mo...         NaN   \n",
       "12832  @AmericanAir lost my cats, missed their flight...         NaN   \n",
       "12833  @AmericanAir lost my cats, missed their flight...         NaN   \n",
       "12834  @AmericanAir don't worry you won't steal my mo...         NaN   \n",
       "\n",
       "      tweet_created      tweet_id            tweet_location  \\\n",
       "12825  2/24/15 9:56  5.702810e+17                       NaN   \n",
       "12826  2/24/15 9:57  5.702810e+17                       NaN   \n",
       "12827  2/24/15 9:57  5.702810e+17                       NaN   \n",
       "12828  2/24/15 9:58  5.702820e+17           indialantic, fl   \n",
       "12829  2/24/15 9:58  5.702820e+17           indialantic, fl   \n",
       "12830  2/24/15 9:58  5.702820e+17                       NaN   \n",
       "12831  2/24/15 9:59  5.702820e+17  Greater New England Area   \n",
       "12832  2/24/15 9:59  5.702820e+17           City by the Bay   \n",
       "12833  2/24/15 9:59  5.702820e+17           City by the Bay   \n",
       "12834  2/24/15 9:59  5.702820e+17  Greater New England Area   \n",
       "\n",
       "                    user_timezone  \n",
       "12825                         NaN  \n",
       "12826  Eastern Time (US & Canada)  \n",
       "12827  Eastern Time (US & Canada)  \n",
       "12828  Eastern Time (US & Canada)  \n",
       "12829  Eastern Time (US & Canada)  \n",
       "12830  Eastern Time (US & Canada)  \n",
       "12831                       Quito  \n",
       "12832  Eastern Time (US & Canada)  \n",
       "12833  Eastern Time (US & Canada)  \n",
       "12834                       Quito  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('tweet_created',inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13:** show that the elements of the column `tweet_created` are of string (`str`) type. [Hint: it is enough if you show this for only one element of the column, for example by using `.at[...]` to access the values of a DataFrame.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['tweet_created'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 14:** as can be seen in the column `tweet_created`, all tweets in our dataset were sent on 9 consecutive days in February 2015. Add a new column called `day` to the DataFrame `df`. The elements of this column should represent the day on which the tweet was created (e.g. `19` for a tweet created on 19 February 2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = df['tweet_created'].str.split('/').apply(pd.Series)[1]\n",
    "df['days'] = days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 15:** print a frequency table for the total number of tweets per day. Sort the table by day, starting with the earliest day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16       4\n",
       "17    1231\n",
       "18    1165\n",
       "19    1184\n",
       "20    1298\n",
       "21    1373\n",
       "22    2744\n",
       "23    2661\n",
       "24    1175\n",
       "Name: days, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['days'].value_counts().sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
