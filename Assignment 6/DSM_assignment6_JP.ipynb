{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "\n",
    "**Deadline**:  16/10/2019, 9.59am\n",
    "\n",
    "**Names and student numbers:**\n",
    "1. name (student number)\n",
    "2. ...\n",
    "3. ...\n",
    "\n",
    "**Declaration of Originality**\n",
    "\n",
    "We whose names are given under 1., 2. and 3. above declare that:\n",
    "1. These solutions are solely our own work.\n",
    "2. We have not made (part of) these solutions available to any other student.\n",
    "\n",
    "## Instructions for completing and submitting the assignment\n",
    "Please pay attention to the following instructions:\n",
    "1. Please follow carefully the steps outlined in the assignment. If you cannot solve an exercise and this hinders continuing with subsequent exercises, try to find a way to work around it and give a clear explanation for the solution you have chosen.\n",
    "2. Submit your work in the form of a Jupyter notebook via Canvas, before the deadline. Your notebook should not give errors when executed with `Run All`.\n",
    "4. You are allowed to work on the assignment in groups of 2 or 3 students and to submit together. Before you submit, you and your team members have to register as an **Assignment group** on Canvas. Only a single member of each group has to submit the notebook. Please do **NOT** submit the same notebook multiple times!\n",
    "5. Please write your names also inside this markdown cell, under **Names and student numbers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "In this assignment you have to develop a classification model. You will be given a training set of 528 datapoints. Using the techniques presented in this course, we ask you to come up with a model that has the best generalization performance. This performance will be assessed on a test dataset of 462 datapoints, which is not available to you. The assignment is also a competition: your mark depends (partly) on how well your model does compared to those of other groups and the three groups with the best performing model will be highlighted.\n",
    "\n",
    "### The data\n",
    "The training data can be found in the file `DSM_assignment6_training_data.csv` on Canvas. It consists of a two-dimensional comma-separated matrix of 528 rows and 11 columns. Each row is a datapoint, consisting of 10 input variables and 1 target variable. The target variable, which is an integer from the set {0,1,...,10} representing the class, is the last column of the matrix.\n",
    "\n",
    "### Submitting your work\n",
    "Your work in this Jupyter notebook consists of two parts. **Part 1** is used to train, create and evaluate your best performing model. In the first cell, you have to train your best performing model on the training data. The code to load the training data is already given. Furthermore, in that same cell you have to create a function called `best_model`. This function has a single input argument, which is a 2-dimensional NumPy array with an arbitrary number of rows and 10 columns (e.g. the input features `X` of the training data). The function should return a 1-dimensional array with the predictions of your best model for the datapoints in the input argument, where each prediction should be an integer from the set {0,1,...,10}. Hence, the number of elements in this 1-dimensional array should be equal to the number of rows of the 2-dimensional array used as input argument.\n",
    "\n",
    "In the second cell, we are using a testset called `DSM_assignment6_test_data.csv` of 462 datapoints to assess the generalization performance of your function `best_model`. Of course, the testset is only available to the teachers. The code in the second cell may not be changed!!! It will be used by the teachers to compute the generalization performance of your best model. On Canvas, you can find a file called `DSM_assignment6_FAKE_test_data.csv`. This is a 2-dimensional array of completely random numbers (fake data), having the same dimensions as the dataset in `DSM_assignment6_test_data.csv`. If you put this file in the same folder as this Jupyter notebook, you can test whether your function `best_model` is defined correctly by checking if the second cell runs without errors. Since the numbers in `DSM_assignment6_FAKE_test_data.csv` are fake data, they **cannot** be used to estimate the performance of your `best_model`. **AFTER TRAINING AND CREATING YOUR BEST MODEL IN THE FIRST CELL, THE SECOND CELL SHOULD RUN WITHOUT ERRORS!!!** If this is not the case, your work will **not** be marked. \n",
    "\n",
    "In **Part 2** of the notebook, you will present your analysis of the classification problem and the steps you have taken to arrive at your best model. Here, you have to explain and perform all the methods that you have used to identify your best model. As in all exercises, please make sure all steps are well motivated and presented in a clear and structured manner. We recommend using visualization methods (e.g., plots with matplotlib), if applicable, to clarify your work.\n",
    "\n",
    "### Example\n",
    "As an example, in this notebook we have defined a `best_model` that randomly assigns a class to every new observation. As expected, the obtained accuracy of this primitive model is around $1/11=0.0909$, since there are 11 classes.\n",
    "\n",
    "### Allowed methods\n",
    "Any of the methods discussed in the course may be used. You are also free to use generalizations of these methods. If you doubt whether your method is allowed, please consult with the teachers. \n",
    "\n",
    "Furthermore, you are allowed to use libraries like scikit-learn, but you are not required to use them.\n",
    "\n",
    "### The competition\n",
    "The generalization performance of your best model is assessed by the **accuracy**, which we define as the proportion of correctly predicted classes, on a secret test dataset consisting of 462 datapoints. You may assume that all datapoints in the training and test set are i.i.d. The scores will be ranked and the top-three groups and their scores will be announced.\n",
    "\n",
    "### The marking\n",
    "As can be seen in the rubric on Canvas, 20% of your mark will depend on the generalization performance of your best model, compared to the best models of your peers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: training, creating and evaluating your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# USE THIS CELL TO TRAIN AND CREATE YOUR BEST MODEL # \n",
    "#####################################################\n",
    "\n",
    "# loading the training data\n",
    "training_data = np.genfromtxt(\"DSM_assignment6_training_data.csv\", delimiter=',')\n",
    "X = training_data[:,:-1]\n",
    "y = training_data[:,-1].astype(int)\n",
    "K_classes = np.unique(y).shape[0]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "def best_model(X_new):\n",
    "    \n",
    "    N_new = X_new.shape[0]\n",
    "    \n",
    "    return np.random.randint(11, size=N_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation coefficient matrix of X\n",
    "#pd.DataFrame(np.corrcoef(X, rowvar = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9488636363636364"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kNN(X_new, X, y, k):\n",
    "    \n",
    "    predictions = np.array([], dtype=int)\n",
    "    \n",
    "    for x in X_new:\n",
    "        \n",
    "        distances = np.linalg.norm(X-x, axis=1)\n",
    "        indices = np.argpartition(distances, k-1)[:k]\n",
    "        \n",
    "        predictions = np.append(predictions, np.argmax(np.bincount(y[indices])))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def kNN_CV_accuracy(X, y, k):\n",
    "    \n",
    "    N = len(X)\n",
    "    \n",
    "    errors = np.array([y[i] == kNN([X[i]], np.delete(X, i, axis=0), np.delete(y, i), k) for i in range(N)])\n",
    "    \n",
    "    return np.mean(errors)\n",
    "\n",
    "kNN_CV_accuracy(X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def accuracy_lists(X,y,k):\n",
    "\n",
    "    acc_list = np.array([])\n",
    "    k_list = np.arange(1,k+1)\n",
    "\n",
    "    for i in range(1,k+1):\n",
    "        acc_list = np.append(acc_list, kNN_CV_accuracy(X,y,i))\n",
    "    \n",
    "    return k_list, acc_list\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.plot(accuracy_lists(X,y,40)[0], accuracy_lists(X,y,40)[1], '-o', color='red')\n",
    "\n",
    "ax1.set_xlabel('K - Neighbours')\n",
    "\n",
    "ax1.set_ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification(X, y, K, dir1, dir2, G=None, title=None):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    colors = ['k','tab:blue','tab:orange','tab:green','tab:red','tab:purple','tab:brown','tab:pink','tab:gray','tab:olive','tab:cyan']\n",
    "    \n",
    "    if np.isscalar(dir1):\n",
    "        dir_temp = np.zeros(X.shape[1])\n",
    "        dir_temp[dir1] = 1.\n",
    "        dir1 = dir_temp\n",
    "        \n",
    "    if np.isscalar(dir2):\n",
    "        dir_temp = np.zeros(X.shape[1])\n",
    "        dir_temp[dir2] = 1.\n",
    "        dir2 = dir_temp\n",
    "    \n",
    "    dir1 = dir1/np.linalg.norm(dir1)\n",
    "    dir2 = dir2/np.linalg.norm(dir2)\n",
    "    \n",
    "    # Plotting the observations in the data set\n",
    "    for k in range(K):\n",
    "        boolean_index = y==k\n",
    "        ax.scatter(np.dot(X[boolean_index], dir1), np.dot(X[boolean_index],dir2), \n",
    "                   c=colors[k])    \n",
    "    \n",
    "    # Creating classification regions\n",
    "    if G:\n",
    "        points = 100\n",
    "        xmin, xmax = ax.get_xlim()\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        x_range = np.linspace(xmin, xmax, points)\n",
    "        y_range = np.linspace(ymin, ymax, points)\n",
    "        xx, yy = np.meshgrid(x_range, y_range)\n",
    "    \n",
    "        G_grid = np.array(list(map(G, np.outer(xx,dir1) + np.outer(yy,dir2)))).reshape(points,points)\n",
    "    \n",
    "        ax.contourf(x_range, y_range, G_grid, 2, alpha=.2, colors=colors)\n",
    "    \n",
    "    ax.set_xlabel(\"Direction 1: {}\".format(dir1))\n",
    "    ax.set_ylabel(\"Direction 2: {}\".format(dir2))\n",
    "\n",
    "    ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "U:  (528, 10) \tD:  (10,) \tV:  (10, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "# PCA #\n",
    "#######\n",
    "\n",
    "U, D, VT = np.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "Z = np.empty(X.shape)\n",
    "Z = U@np.diag(D)\n",
    "\n",
    "print(np.allclose(X, (U*D[None, :])@VT))\n",
    "print(np.allclose(np.identity(U.shape[1]),U.T@U))\n",
    "print(np.allclose(np.identity(VT.shape[1]),VT.T@VT))\n",
    "\n",
    "print(\"U: \",U.shape, \"\\tD: \", D.shape, \"\\tV: \",  VT.shape)\n",
    "\n",
    "# Plotting the results\n",
    "var_explained = D/sum(D)\n",
    "var_explained_sum = np.cumsum(var_explained)\n",
    "\n",
    "x_range = list(range(1,len(var_explained_sum)+1))\n",
    "\n",
    "#fig2 = plt.figure(2, figsize=(8,6))\n",
    "ax1 = fig2.add_subplot(1,1,1)\n",
    "\n",
    "ax1.bar(x_range, var_explained_sum)\n",
    "ax1.set_xlim([0,11])\n",
    "ax1.set_xlabel('Singular values')\n",
    "ax1.set_xticks(np.arange(1,11,step=1));\n",
    "\n",
    "ax1.set_ylabel('Cumulative Variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9753787878787878\n",
      "0.9753787878787878\n",
      "0.9621212121212122\n"
     ]
    }
   ],
   "source": [
    "print(kNN_CV_accuracy(X,y,3))\n",
    "print(kNN_CV_accuracy(Z,y,3))\n",
    "print(kNN_CV_accuracy(Z[:,:5],y,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(528, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Different matrices to train the models with ###\n",
    "\n",
    "Z = U@np.diag(D)\n",
    "Z_reduced = Z[:,:3]\n",
    "\n",
    "def polynomial_features(X, M):\n",
    "    return np.concatenate(tuple([X**(n+1) for n in range(M+1)]), axis=1)\n",
    "\n",
    "Z_reduced_poly = polynomial_features(Z_reduced, 2)\n",
    "Z_reduced_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function to calculate accuracy of different models ###\n",
    "\n",
    "def accuracy(training_method, X, y, K_classes, K_cv=10, runs=1):\n",
    "    \n",
    "    N = len(y)\n",
    "    \n",
    "    misclassifications = np.array([])\n",
    "    for run in range(runs):\n",
    "        \n",
    "        cv_folds = KFold(n_splits=K_cv, shuffle=True) # Randomly creating new folds for each run\n",
    "        \n",
    "        for indices_train, indices_test in cv_folds.split(X):\n",
    "            \n",
    "            X_train = X[indices_train]\n",
    "            y_train = y[indices_train]\n",
    "            X_test = X[indices_test]\n",
    "            y_test = y[indices_test]\n",
    "\n",
    "            G_fitted = training_method(X_train, y_train, K_classes) # Fitting model in training data\n",
    "            y_fitted_test = G_fitted(X_test) # Using fitted model to predict on test data\n",
    "\n",
    "            no_misclassifications = np.sum(y_fitted_test != y_test) # Counting number of prediction errors test data\n",
    "            misclassifications = np.append(misclassifications, no_misclassifications)\n",
    "    \n",
    "    accuracy = 1 - np.sum(misclassifications)/(N*runs)\n",
    "    std_error = np.std(misclassifications, ddof=1)*np.sqrt(K_cv/runs)/N\n",
    "    \n",
    "    return accuracy, std_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "### LDA ###\n",
    "###########\n",
    "\n",
    "# Use only y to detect ratio of a class, pi\n",
    "def get_prior_probs(y):\n",
    "    \n",
    "    N = len(y)\n",
    "    freqs = np.unique(y, return_counts = True)[1]\n",
    "    \n",
    "    return freqs/N\n",
    "\n",
    "# Find mu as matrix with rows K and columns 4 with mean of features per class \n",
    "def get_centroids(X, y, K_classes):\n",
    "    \n",
    "    centroids = np.zeros((K_classes, X.shape[1]))\n",
    "    \n",
    "    for k in range(K_classes):  \n",
    "        centroids[k] = np.mean(X[y==k], axis = 0)\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "# Find the 4 by 4 covariance matrix which is the same per class\n",
    "def get_within_class_covariance_matrix(X, y, K_classes, centroids):\n",
    "    \n",
    "    N = len(y)\n",
    "    X_diff = X - np.array([centroids[k] for k in y])\n",
    "    \n",
    "    return (X_diff.T @ X_diff)/(N-K_classes)\n",
    "\n",
    "centroids = get_centroids(X, y, K_classes)\n",
    "\n",
    "# Obtain the delta\n",
    "def train_lda_classification(X, y, K_classes):\n",
    "    \n",
    "    probs = get_prior_probs(y)\n",
    "    centroids = get_centroids(X, y, K_classes)\n",
    "    cov = get_within_class_covariance_matrix(X, y, K_classes, centroids)\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    \n",
    "    def G(X_new):\n",
    "        \n",
    "        deltas = np.zeros((X_new.shape[0], K_classes))\n",
    "        for k in range(K_classes):\n",
    "            deltas[:,k] = (X_new - centroids[k]/2) @ inv_cov @ centroids[k] + np.log(probs[k])\n",
    "        \n",
    "        return np.argmax(deltas, axis=1)\n",
    "    \n",
    "    return G\n",
    "\n",
    "G_fitted = train_lda_classification(X, y, K_classes)\n",
    "#G_fitted(X)\n",
    "accuracy(train_lda_classification, X, y , K_classes, K_cv=10, runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6117424242424243, 0.029238727719468206)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance per eigenvalue/linear discriminant:\n",
      "eigenvalue 1: 92.82%\n",
      "eigenvalue 2: 4.82%\n",
      "eigenvalue 3: 1.42%\n",
      "eigenvalue 4: 0.50%\n",
      "eigenvalue 5: 0.22%\n",
      "eigenvalue 6: 0.12%\n",
      "eigenvalue 7: 0.08%\n",
      "eigenvalue 8: 0.01%\n",
      "eigenvalue 9: 0.00%\n",
      "eigenvalue 10: 0.00%\n",
      "accuracy taking into account the first 1 linear discriminants: (0.2526515151515152, 0.006099579121463848)\n",
      "accuracy taking into account the first 2 linear discriminants: (0.5916666666666667, 0.0062746762682238276)\n",
      "accuracy taking into account the first 3 linear discriminants: (0.6350378787878788, 0.006702063408143739)\n",
      "accuracy taking into account the first 4 linear discriminants: (0.6424242424242423, 0.0067420846101904275)\n",
      "accuracy taking into account the first 5 linear discriminants: (0.6488636363636364, 0.0064741853479721185)\n",
      "accuracy taking into account the first 6 linear discriminants: (0.6539772727272728, 0.005696815987854695)\n",
      "accuracy taking into account the first 7 linear discriminants: (0.6535984848484848, 0.005899531315566276)\n",
      "accuracy taking into account the first 8 linear discriminants: (0.6388257575757577, 0.005990704699542214)\n",
      "accuracy taking into account the first 9 linear discriminants: (0.6325757575757576, 0.00681541793451421)\n",
      "accuracy taking into account the first 10 linear discriminants: (0.6225378787878788, 0.0063432191650934396)\n",
      "accuracy taking into account the first 1 lin comb and 1 pol features: (0.2367424242424242, 0.020369022480936465)\n",
      "accuracy taking into account the first 1 lin comb and 2 pol features: (0.2821969696969697, 0.017277692150762636)\n",
      "accuracy taking into account the first 1 lin comb and 3 pol features: (0.29734848484848486, 0.01944813358680475)\n",
      "accuracy taking into account the first 1 lin comb and 4 pol features: (0.2859848484848485, 0.011310904587859164)\n",
      "accuracy taking into account the first 1 lin comb and 5 pol features: (0.30113636363636365, 0.03345959595959596)\n",
      "accuracy taking into account the first 1 lin comb and 6 pol features: (0.30113636363636365, 0.019242109411777997)\n",
      "accuracy taking into account the first 1 lin comb and 7 pol features: (0.2935606060606061, 0.021137208387352537)\n",
      "accuracy taking into account the first 1 lin comb and 8 pol features: (0.2954545454545454, 0.018897259529161322)\n",
      "accuracy taking into account the first 1 lin comb and 9 pol features: (0.2992424242424242, 0.021869328378394916)\n",
      "accuracy taking into account the first 1 lin comb and 10 pol features: (0.10037878787878785, 0.011025409846321327)\n",
      "accuracy taking into account the first 2 lin comb and 1 pol features: (0.5946969696969697, 0.013888888888888888)\n",
      "accuracy taking into account the first 2 lin comb and 2 pol features: (0.5757575757575757, 0.015515411272025896)\n",
      "accuracy taking into account the first 2 lin comb and 3 pol features: (0.6022727272727273, 0.028233181534088256)\n",
      "accuracy taking into account the first 2 lin comb and 4 pol features: (0.5984848484848485, 0.016892788081135923)\n",
      "accuracy taking into account the first 2 lin comb and 5 pol features: (0.6193181818181819, 0.018394952379208924)\n",
      "accuracy taking into account the first 2 lin comb and 6 pol features: (0.6231060606060606, 0.01839495237920892)\n",
      "accuracy taking into account the first 2 lin comb and 7 pol features: (0.6420454545454546, 0.022665811958353845)\n",
      "accuracy taking into account the first 2 lin comb and 8 pol features: (0.6458333333333333, 0.023460737596037937)\n",
      "accuracy taking into account the first 2 lin comb and 9 pol features: (0.2367424242424242, 0.045703757064995625)\n",
      "accuracy taking into account the first 2 lin comb and 10 pol features: (0.09469696969696972, 0.012562972690740151)\n",
      "accuracy taking into account the first 3 lin comb and 1 pol features: (0.634469696969697, 0.018308080808080808)\n",
      "accuracy taking into account the first 3 lin comb and 2 pol features: (0.6420454545454546, 0.01795639223905037)\n",
      "accuracy taking into account the first 3 lin comb and 3 pol features: (0.6761363636363636, 0.021585001259190353)\n",
      "accuracy taking into account the first 3 lin comb and 4 pol features: (0.7234848484848485, 0.014724625997084094)\n",
      "accuracy taking into account the first 3 lin comb and 5 pol features: (0.7443181818181819, 0.013613547129323122)\n",
      "accuracy taking into account the first 3 lin comb and 6 pol features: (0.740530303030303, 0.02462121212121212)\n",
      "accuracy taking into account the first 3 lin comb and 7 pol features: (0.7443181818181819, 0.018780902500812522)\n",
      "accuracy taking into account the first 3 lin comb and 8 pol features: (0.10795454545454541, 0.02335858585858586)\n",
      "accuracy taking into account the first 3 lin comb and 9 pol features: (0.10227272727272729, 0.011007320564496652)\n",
      "accuracy taking into account the first 3 lin comb and 10 pol features: (0.10606060606060608, 0.012876311903012085)\n",
      "accuracy taking into account the first 4 lin comb and 1 pol features: (0.6439393939393939, 0.023756171366447955)\n",
      "accuracy taking into account the first 4 lin comb and 2 pol features: (0.6666666666666667, 0.021905746935476606)\n",
      "accuracy taking into account the first 4 lin comb and 3 pol features: (0.7329545454545454, 0.026552703086885218)\n",
      "accuracy taking into account the first 4 lin comb and 4 pol features: (0.7708333333333334, 0.012451441239467186)\n",
      "accuracy taking into account the first 4 lin comb and 5 pol features: (0.8143939393939394, 0.018253576129799193)\n",
      "accuracy taking into account the first 4 lin comb and 6 pol features: (0.7992424242424243, 0.014451418108913634)\n",
      "accuracy taking into account the first 4 lin comb and 7 pol features: (0.37689393939393945, 0.04332206682903476)\n",
      "accuracy taking into account the first 4 lin comb and 8 pol features: (0.125, 0.007885098482826262)\n",
      "accuracy taking into account the first 4 lin comb and 9 pol features: (0.10795454545454541, 0.010732323232323232)\n",
      "accuracy taking into account the first 4 lin comb and 10 pol features: (0.08333333333333337, 0.017219926385083153)\n",
      "accuracy taking into account the first 5 lin comb and 1 pol features: (0.6590909090909092, 0.021686318228936453)\n",
      "accuracy taking into account the first 5 lin comb and 2 pol features: (0.7348484848484849, 0.016702975448640092)\n",
      "accuracy taking into account the first 5 lin comb and 3 pol features: (0.7784090909090909, 0.02017240569276573)\n",
      "accuracy taking into account the first 5 lin comb and 4 pol features: (0.865530303030303, 0.015321541792312626)\n",
      "accuracy taking into account the first 5 lin comb and 5 pol features: (0.8598484848484849, 0.018981434821177916)\n",
      "accuracy taking into account the first 5 lin comb and 6 pol features: (0.14015151515151514, 0.017219926385083153)\n",
      "accuracy taking into account the first 5 lin comb and 7 pol features: (0.09659090909090906, 0.008493449524667747)\n",
      "accuracy taking into account the first 5 lin comb and 8 pol features: (0.08712121212121215, 0.014615955685341195)\n",
      "accuracy taking into account the first 5 lin comb and 9 pol features: (0.09469696969696972, 0.010101010101010102)\n",
      "accuracy taking into account the first 5 lin comb and 10 pol features: (0.08143939393939392, 0.012704931690339713)\n",
      "accuracy taking into account the first 6 lin comb and 1 pol features: (0.6590909090909092, 0.016702975448640092)\n",
      "accuracy taking into account the first 6 lin comb and 2 pol features: (0.7272727272727273, 0.016750630254320203)\n",
      "accuracy taking into account the first 6 lin comb and 3 pol features: (0.8352272727272727, 0.016474732766035217)\n",
      "accuracy taking into account the first 6 lin comb and 4 pol features: (0.9185606060606061, 0.011657945273118302)\n",
      "accuracy taking into account the first 6 lin comb and 5 pol features: (0.32765151515151514, 0.028549038016654076)\n",
      "accuracy taking into account the first 6 lin comb and 6 pol features: (0.09280303030303028, 0.009126788064899596)\n",
      "accuracy taking into account the first 6 lin comb and 7 pol features: (0.06818181818181823, 0.016414141414141416)\n",
      "accuracy taking into account the first 6 lin comb and 8 pol features: (0.09090909090909094, 0.012626262626262628)\n",
      "accuracy taking into account the first 6 lin comb and 9 pol features: (0.05681818181818177, 0.013773626407368324)\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "### Reduced Rank LDA ###\n",
    "########################\n",
    "\n",
    "def get_between_class_covariance(centroids, K_classes):\n",
    "    return np.dot(centroids.T, centroids)/(K_classes - 1)\n",
    "\n",
    "def get_linear_discriminants(X, y, K_classes):\n",
    "    \n",
    "    centroids = get_centroids(X, y, K_classes)\n",
    "\n",
    "    Sigma = get_within_class_covariance_matrix(X, y, K_classes, centroids)\n",
    "\n",
    "    B = get_between_class_covariance(centroids, K_classes)\n",
    "    \n",
    "    eig_vals, eig_vecs = np.linalg.eig(np.dot(np.linalg.inv(Sigma), B))\n",
    "    \n",
    "    return eig_vals.real, eig_vecs.real\n",
    "\n",
    "eig_vals, eig_vecs = get_linear_discriminants(X, y, K_classes)\n",
    "\n",
    "print(\"Explained variance per eigenvalue/linear discriminant:\")\n",
    "for i, eig_val in enumerate(eig_vals):\n",
    "    print(\"eigenvalue {0}: {1:.2%}\".format(i+1, np.abs(eig_val/sum(eig_vals))))\n",
    "    \n",
    "# Projecting onto the linear discriminant (directions)\n",
    "Z = np.dot(X, eig_vecs)\n",
    "\n",
    "# Computing accuracies\n",
    "for i in range(len(eig_vals)):\n",
    "    \n",
    "    Z_reduced = Z[:,:i+1]\n",
    "    \n",
    "    acc = accuracy(train_lda_classification, Z_reduced, y, K_classes, K_cv=10, runs=10)\n",
    "    print(\"accuracy taking into account the first {0} linear discriminants: {1}\".format(i+1, acc))\n",
    "\n",
    "for i in range(6):\n",
    "    Z_reduced = Z[:,:i+1]\n",
    "    for j in range(10):\n",
    "        poly = PolynomialFeatures(j+1, include_bias=False)\n",
    "        Z_polynomial = poly.fit_transform(Z_reduced)\n",
    "    \n",
    "        acc = accuracy(train_lda_classification, Z_polynomial, y , K_classes, K_cv=10, runs=1)\n",
    "        print(\"accuracy taking into account the first {0} lin comb and {1} pol features: {2}\".format(i+1, j+1, acc))\n",
    "\n",
    "        \n",
    "# Plotting\n",
    "#G_fitted =  train_lda_classification(Z_polynomial, y, K_classes)\n",
    "#plot_classification(Z_polynomial, y, K_classes, 0, 1, G=G_fitted)\n",
    "\n",
    "\n",
    "#Z_reduced_poly = polynomial_features(Z_reduced, 2)\n",
    "#accuracy(train_lda_classification, Z_reduced_poly, y , K_classes, K_cv=10, runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "### QDA ###\n",
    "###########\n",
    "\n",
    "def get_per_class_covariance_matrix(X, y, K_classes, centroids):\n",
    "    X_diff = X - np.array([centroids[k] for k in y])\n",
    "    class_cov = []\n",
    "    \n",
    "    for k in range(K_classes):\n",
    "        class_cov.append(np.sum(np.array([np.outer(Help, Help) for Help in X_diff[y == k]]), axis=0)/(sum(y==k)-1))\n",
    "        \n",
    "    return class_cov\n",
    "\n",
    "# Obtain delta\n",
    "def train_qda_classification(X, y, K_classes):\n",
    "\n",
    "    probs = get_prior_probs(y)\n",
    "    centroids = get_centroids(X, y, K_classes)\n",
    "    class_cov = get_per_class_covariance_matrix(X, y, K_classes, centroids)\n",
    "    inv_cov = np.linalg.inv(class_cov)\n",
    "    def G(X_new):\n",
    "        \n",
    "        deltas = np.zeros((X_new.shape[0], K_classes))\n",
    "        for k in range(K_classes):\n",
    "            deltas[:,k] = np.diagonal(-((X_new - centroids[k]) @ inv_cov[k] @ (X_new - centroids[k]).T)/2 + np.log(probs[k]) - 1/2 * np.log(np.linalg.det(class_cov[k])))\n",
    "        return np.argmax(deltas, axis=1)\n",
    "    return G\n",
    "\n",
    "accuracy(train_qda_classification, X, y , K_classes, K_cv=8, runs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.922979797979798, 0.006112308741990999)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(train_qda_classification, X, y , K_classes, K_cv=8, runs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.09134199134199135\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#    !!!DO NOT CHANGE THE CODE IN THIS CELL!!!       #\n",
    "# THIS CELL IS USED FOR EVALUATING YOUR BEST MODEL.  #  \n",
    "# AFTER TRAINING AND CREATING YOUR BEST MODEL IN THE #\n",
    "# PREVIOUS CELL, THIS CELL SHOULD RUN WITHOUT ERRORS # \n",
    "######################################################\n",
    "\n",
    "# Determining which test data will be used. If real test \n",
    "# data is available, it will be used. Otherwise, the \n",
    "# fake test data will be used.\n",
    "if os.path.exists(\"DSM_assignment6_test_data.csv\"):\n",
    "    test_data_filename = \"DSM_assignment6_test_data.csv\"\n",
    "elif os.path.exists(\"DSM_assignment6_FAKE_test_data.csv\"):\n",
    "    test_data_filename = \"DSM_assignment6_FAKE_test_data.csv\"\n",
    "else:\n",
    "    test_data_filename = None\n",
    "    print(\"ERROR: Test data is missing!\")\n",
    "    \n",
    "if test_data_filename:\n",
    "\n",
    "    # loading the test data    \n",
    "    test_data = np.genfromtxt(test_data_filename, delimiter=',')\n",
    "    X_test = test_data[:,:-1]\n",
    "    y_test = test_data[:,-1].astype(int)\n",
    "\n",
    "    # making predictions and computing the accuracy (by averaging over 20 runs to reduce randomness)\n",
    "    accuracies= np.array([])\n",
    "    for i in range(20):\n",
    "        predictions = best_model(X_test)\n",
    "        accuracy = np.mean(predictions == y_test)\n",
    "        accuracies = np.append(accuracies, accuracy)\n",
    "\n",
    "    print(\"The accuracy is: \", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
